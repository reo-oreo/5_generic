{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 汎用スクリプト　base\n",
    "概要：このファイルは①データ読み込み、②可視化、③前処理、④分析までを型化し、汎用利用を考えたもの\n",
    "\n",
    "活用方法：記載されているコードをベースにし、プロセスごとにコードを整理し、データサイエンスプロセスを効率化\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⓪ライブラリ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostLibraryNotFound",
     "evalue": "Cannot find XGBoost Library in the candidate path, did you install compilers and run build.sh in root path?\nList of candidates:\nC:\\Users\\10696\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\xgboost.dll\nC:\\Users\\10696\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\../../lib/xgboost.dll\nC:\\Users\\10696\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\./lib/xgboost.dll\nC:\\Users\\10696\\AppData\\Local\\Continuum\\anaconda3\\xgboost\\xgboost.dll\nC:\\Users\\10696\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\../../windows/x64/Release/xgboost.dll\nC:\\Users\\10696\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\./windows/x64/Release/xgboost.dll",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostLibraryNotFound\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-06ab7137e8e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;31m# import xgboost as xgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mlgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBooster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrabit\u001b[0m                   \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;31m# load the XGBoost library globally\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m \u001b[0m_LIB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_load_lib\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_load_lib\u001b[1;34m()\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_load_lib\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[1;34m\"\"\"Load xgboost Library.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m     \u001b[0mlib_paths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_lib_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlib_paths\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\libpath.py\u001b[0m in \u001b[0;36mfind_lib_path\u001b[1;34m()\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[1;34m'Cannot find XGBoost Library in the candidate path, '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[1;34m'did you install compilers and run build.sh in root path?\\n'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m             'List of candidates:\\n' + ('\\n'.join(dll_path)))\n\u001b[0m\u001b[0;32m     49\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlib_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mXGBoostLibraryNotFound\u001b[0m: Cannot find XGBoost Library in the candidate path, did you install compilers and run build.sh in root path?\nList of candidates:\nC:\\Users\\10696\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\xgboost.dll\nC:\\Users\\10696\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\../../lib/xgboost.dll\nC:\\Users\\10696\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\./lib/xgboost.dll\nC:\\Users\\10696\\AppData\\Local\\Continuum\\anaconda3\\xgboost\\xgboost.dll\nC:\\Users\\10696\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\../../windows/x64/Release/xgboost.dll\nC:\\Users\\10696\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\./windows/x64/Release/xgboost.dll"
     ]
    }
   ],
   "source": [
    "#データ加工ライブラリ\n",
    "import pandas as pd\n",
    "\n",
    "#可視化ライブラリ\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#label encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#統計\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew\n",
    "from scipy.special import boxcox1p\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "import warnings\n",
    "\n",
    "#学習モデル\n",
    "\n",
    "#線形モデル一覧　https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model\n",
    "#線形モデルの説明　https://scikit-learn.org/stable/modules/linear_model.html#linear-model\n",
    "\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# import xgboost as xgb\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ①データ読み込み\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 進め方\n",
    "\n",
    "■流れ\n",
    "文字コードによって適切に読み込まれない場合がある場合は、以下の様に進める\n",
    "\n",
    "①文字コードの特定(nkf)　②pandas.read_csvの引数指定\n",
    "\n",
    "■文字コード\n",
    "\n",
    "https://dev.classmethod.jp/tool/character-code-and-line-feed-code-converting-tools-matome/\n",
    "\n",
    "■公式　pandas.read_csv\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csvファイルの読み込み\n",
    "df_train=pd.read_csv('train.csv')\n",
    "df_test=pd.read_csv('test.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ②可視化\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "セルを右クリックして、variable inspectorを利用すると、データの表を確認できる\n",
    "\n",
    "より複雑な可視化をする場合は、BIツールで実施したほうが費用対効果高そう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#列名の確認\n",
    "print(df_train.columns)\n",
    "print(\"-----------------------\")\n",
    "\n",
    "#目的変数の基本統計量確認\n",
    "print(df_train['SalePrice'].describe())\n",
    "print(\"-----------------------\")\n",
    "\n",
    "#目的変数をヒストグラムでの可視化\n",
    "sns.distplot(df_train['SalePrice'])\n",
    "plt.show()\n",
    "\n",
    "#データフレーム情報　\n",
    "#フレームの見方\n",
    "# data_column(項目名) num(数が行数とあっていれば、欠損なし) int64,float64,object(object⇛質的変数　int,float⇛量的変数)\n",
    "\n",
    "print(\"-----------------------\")\n",
    "print(\"データフレーム情報_train\",df_train.info())\n",
    "\n",
    "print(\"-----------------------\")\n",
    "print(\"データフレーム情報_test\",df_test.info())\n",
    "\n",
    "#相関ヒートマップ\n",
    "corrmat=df_train.corr()\n",
    "f,ax=plt.subplots(figsize=(12,9))\n",
    "sns.heatmap(corrmat,vmax=0.8,square=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ③前処理\n",
    "各変数において必要な処理は以下のようになる。（個人的な理解）特徴量エンジニアリングの世界なので、まだ完全に定石手法を理解しきれていない、\n",
    "\n",
    "①特徴選択\n",
    "\n",
    "②特徴データに対する欠損対応\n",
    "\n",
    "③適切なデータ変換(量⇛質　質⇛量)\n",
    "\n",
    "③説明変数に対して、正規化対応"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徴選択"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#目的変数と説明変数の相関高TOP10\n",
    "#saleprice correlation matrix\n",
    "k = 10 #number of variables for heatmap\n",
    "cols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index\n",
    "\n",
    "cm = np.corrcoef(df_train[cols].values.T)\n",
    "sns.set(font_scale=1.25)\n",
    "hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特徴量選択のロジック\n",
    "\n",
    "まず'OverallQual','GrLivArea','TotalBsmtSF'は'SalePrice'への相関が高い。\n",
    "　⇛特徴量に入れよう\n",
    "\n",
    "'GarageCars' と'GarageArea'は目的変数に対して、相関が強い変数ではあるが、ガレージに入る車の数はガレージの広さの結果によるものであるので、多重共線性があるといえる。\n",
    "　⇛どちらか一つを選択する必要があるので、目的変数への相関が強い'GarageCars'を選択する\n",
    " \n",
    "'TotalBsmtSF' と'1stFloor'も多重共線性がありそう、'TotalBsmtSF'を残す。\n",
    "\n",
    "'TotRmsAbvGrd' と'GrLivArea'も多重共線性がありそう\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#特徴量選択\n",
    "feature_column=['OverallQual', 'GarageCars', 'TotalBsmtSF', 'YearBuilt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#散布図による確認\n",
    "sns.set()\n",
    "cols=['SalePrice','OverallQual','GrLivArea','GarageCars','TotalBsmtSF','FullBath','YearBuilt']\n",
    "sns.pairplot(df_train[cols],height=2.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the numbers of samples and features\n",
    "print(\"The train data size before dropping Id feature is : {} \".format(df_train.shape))\n",
    "print(\"The test data size before dropping Id feature is : {} \".format(df_test.shape))\n",
    "\n",
    "#Save the 'Id' column\n",
    "train_ID = df_train['Id']\n",
    "test_ID = df_test['Id']\n",
    "\n",
    "#Now drop the  'Id' colum since it's unnecessary for  the prediction process.\n",
    "df_train.drop(\"Id\", axis = 1, inplace = True)\n",
    "df_test.drop(\"Id\", axis = 1, inplace = True)\n",
    "\n",
    "#check again the data size after dropping the 'Id' variable\n",
    "print(\"\\nThe train data size after dropping Id feature is : {} \".format(df_train.shape)) \n",
    "print(\"The test data size after dropping Id feature is : {} \".format(df_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 欠損対応"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#テストデータと学習データの結合\n",
    "ntrain = df_train.shape[0]\n",
    "ntest = df_test.shape[0]\n",
    "y_train = df_train.SalePrice.values\n",
    "all_data = pd.concat((df_train, df_test)).reset_index(drop=True)\n",
    "all_data.drop(['SalePrice'], axis=1, inplace=True)\n",
    "print(\"all_data size is : {}\".format(all_data.shape))\n",
    "\n",
    "#欠損値の確認\n",
    "all_data_na = (all_data.isnull().sum() / len(all_data)) * 100\n",
    "all_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)[:30]\n",
    "missing_data = pd.DataFrame({'Missing Ratio' :all_data_na})\n",
    "missing_data.head(20)\n",
    "\n",
    "\n",
    "#欠損対応 (データ項目説明参照)\n",
    "\n",
    "#None置換\n",
    "all_data[\"PoolQC\"]=all_data[\"PoolQC\"].fillna(\"None\")\n",
    "all_data[\"MiscFeature\"]=all_data[\"MiscFeature\"].fillna(\"None\")\n",
    "all_data[\"Alley\"]=all_data[\"Alley\"].fillna(\"None\")\n",
    "all_data[\"Fence\"]=all_data[\"Fence\"].fillna(\"None\")\n",
    "all_data[\"FireplaceQu\"]=all_data[\"FireplaceQu\"].fillna(\"None\")\n",
    "\n",
    "for col in ('GarageType','GarageFinish','GarageQual','GarageCond'):\n",
    "    all_data[col]=all_data[col].fillna('None')\n",
    "    \n",
    "for col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n",
    "    all_data[col] = all_data[col].fillna('None')\n",
    "    \n",
    "all_data[\"MasVnrType\"] = all_data[\"MasVnrType\"].fillna(\"None\")\n",
    "all_data['MSSubClass'] = all_data['MSSubClass'].fillna(\"None\")\n",
    "\n",
    "#0置換\n",
    "for col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):\n",
    "    all_data[col]=all_data[col].fillna(0)\n",
    "    \n",
    "for col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n",
    "    all_data[col] = all_data[col].fillna(0)\n",
    "\n",
    "all_data[\"MasVnrArea\"] = all_data[\"MasVnrArea\"].fillna(0)\n",
    "\n",
    "#median置換 Neighthood(近所)でグループバイしてやれば、エリア毎のmedianを求めることができる\n",
    "all_data['LotFrontage']=all_data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x:x.fillna(x.median()))\n",
    "\n",
    "all_data['MSZoning']=all_data['MSZoning'].fillna(all_data['MSZoning'].mode()[0])\n",
    "\n",
    "all_data['Electrical']=all_data['Electrical'].fillna(all_data['Electrical'].mode()[0])\n",
    "\n",
    "all_data['KitchenQual']=all_data['KitchenQual'].fillna(all_data['KitchenQual'].mode()[0])\n",
    "\n",
    "all_data['Exterior1st'] = all_data['Exterior1st'].fillna(all_data['Exterior1st'].mode()[0])\n",
    "all_data['Exterior2nd'] = all_data['Exterior2nd'].fillna(all_data['Exterior2nd'].mode()[0])\n",
    "all_data['SaleType'] = all_data['SaleType'].fillna(all_data['SaleType'].mode()[0])\n",
    "\n",
    "#特定の値に置換\n",
    "all_data[\"Functional\"]=all_data[\"Functional\"].fillna(\"Typ\")\n",
    "\n",
    "#列の削除\n",
    "all_data=all_data.drop(['Utilities'],axis=1)\n",
    "\n",
    "#欠損値のあるデータ項目がないか確認する\n",
    "all_data_na = (all_data.isnull().sum() / len(all_data)) * 100\n",
    "all_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)\n",
    "missing_data = pd.DataFrame({'Missing Ratio' :all_data_na})\n",
    "missing_data.head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 量的変数から質的変数へ変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['MSSubClass']=all_data['MSSubClass'].apply(str)\n",
    "\n",
    "all_data['OverallCond']=all_data['OverallCond'].astype(str)\n",
    "\n",
    "all_data['YrSold']=all_data['YrSold'].astype(str)\n",
    "all_data['MoSold']=all_data['MoSold'].astype(str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n",
    "        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n",
    "        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n",
    "        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n",
    "        'YrSold', 'MoSold')\n",
    "# process columns, apply LabelEncoder to categorical features\n",
    "# LabelEncoder:https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\n",
    "\n",
    "for c in cols:\n",
    "    lbl = LabelEncoder() \n",
    "    lbl.fit(list(all_data[c].values)) \n",
    "    all_data[c] = lbl.transform(list(all_data[c].values))\n",
    "\n",
    "# shape        \n",
    "print('Shape all_data: {}'.format(all_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徴量作成\n",
    "地下から2階までの面積を総計して、新しい特徴量を作成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['TotalSF']=all_data['TotalBsmtSF']+all_data['1stFlrSF']+all_data['2ndFlrSF']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 尖度チェック"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#量的変数の抜き出し\n",
    "numeric_feats=all_data.dtypes[all_data.dtypes !=\"object\"].index\n",
    "\n",
    "#尖度一覧\n",
    "skewed_feats=all_data[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "print(\"\\nSkew in numerical features:\\n\")\n",
    "\n",
    "skewness=pd.DataFrame({'Skew':skewed_feats})\n",
    "skewness.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BoxCox変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#正規分布の形にしてくれるみたいだが、なぜそうなるのか理解できていない\n",
    "skewness = skewness[abs(skewness) > 0.75]\n",
    "print(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n",
    "\n",
    "\n",
    "skewed_features = skewness.index\n",
    "lam = 0.15\n",
    "for feat in skewed_features:\n",
    "    #all_data[feat] += 1\n",
    "    all_data[feat] = boxcox1p(all_data[feat], lam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ダミー化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data=pd.get_dummies(all_data)\n",
    "print(all_data.shape)\n",
    "\n",
    "all_data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テストデータと学習データの用意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=all_data[:ntrain]\n",
    "test=all_data[ntrain:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 交差検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds=5\n",
    "\n",
    "def rmsle_cv(model):\n",
    "    kd=KFold(n_folds,shuffle=True,random_state=42).get_n_splits(train.values)\n",
    "    rmse=np.sqrt(-cross_val_score(model,train.values,y_train,scoring=\"neg_mean_squared_error\",cv=kf))\n",
    "    return(rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO\n",
    "外れ値に弱いモデルなので、RobustScalerで対応する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso=make_pipeline(RobustScaler(),Lasso(alpha=0.0005,random_state=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### elastic net regression\n",
    "外れ値対応"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Enet=make_pipeline(RobustScaler(),ElasticNet(alpha=0.0005,l1_ratio=0.9,random_state=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KRR=KernelRidge(alpha=0.6,kernel='polynomial',degree=2,coef0=2.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Bossting regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gboost=GradientBoostingRegressor(n_estimators=3000,learning_rate=0.05,max_depth=4,max_features='sqrt',min_samples_leaf=15,min_samples_split=10,loss='huber',random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb=xgb.XGBRegressor(colsample_bytree=0.463,gamma=0.0468,learning_rate=0.05,max_depth=3,min_child_weight=1.7817,n_estimators=2200,reg_alpha=0.4640,reg_lambda=0.8571,subsample=0.5123,silent=1,random_state=7,nthread=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb=lgb.LGBMRegressor(objective='regression',num_leaves=5,learning_rate=0.05,n_estimators=720,max_bin=55,bagging_fraction=0.8,bagging_freq=5,feature_fraction=0.2319,feature_fraction_seed=9,bagging_seed=9,min_data_in_leaf=6,min_sum_hessian_in_leaf=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルのスコア"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score=rmsle_cv(lasso)\n",
    "print(\"\\nLasso score:{:.4f} ({:.4f})\\n\".format(score.mean(),score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 外れ値対応"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#外れ値対応\n",
    "\n",
    "saleprice_scaled=StandardScaler().fit_transform(df_train['SalePrice'][:,np.newaxis])\n",
    "low_range=saleprice_scaled[saleprice_scaled[:,0].argsort()][:10]\n",
    "high_range=saleprice_scaled[saleprice_scaled[:,0].argsort()[-10:]]\n",
    "print(\"outer range (low) of the distribution\")\n",
    "print(low_range)\n",
    "print(\"\\n outer range (high) pf the destribution\")\n",
    "print(high_range)\n",
    "\n",
    "var='GrLivArea'\n",
    "data=pd.concat([df_train['SalePrice'],df_train[var]],axis=1)\n",
    "data.plot.scatter(x=var,y='SalePrice',ylim=(0,8000000))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#外れ値を削除\n",
    "\n",
    "df_train.sort_values(by='GrLivArea',ascending=False)[:2]\n",
    "sns.distplot(df_train['GrLivArea'])\n",
    "plt.show()\n",
    "\n",
    "var = 'GrLivArea'\n",
    "data = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\n",
    "data.plot.scatter(x=var, y='SalePrice', ylim=(0,800000));\n",
    "\n",
    "var='TotalBsmtSF'\n",
    "data=pd.concat([df_train['SalePrice'],df_train[var]],axis=1)\n",
    "data.plot.scatter(x=var,y='SalePrice',ylim=(0,800000))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ確認\n",
    "\n",
    "正規性\n",
    "\n",
    "分散均一性\n",
    "\n",
    "線形性\n",
    "\n",
    "誤差相関\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ヒストグラムと正規確率分布\n",
    "sns.distplot(df_train['SalePrice'],fit=norm)\n",
    "fig=plt.figure()\n",
    "res=stats.probplot(df_train['SalePrice'],plot=plt)\n",
    "plt.show()\n",
    "\n",
    "#データ変形\n",
    "df_train['GrLivArea']=np.log(df_train['GrLivArea'])\n",
    "\n",
    "#変形後のヒストグラムと正規確率分布\n",
    "sns.distplot(df_train['GrLivArea'],fit=norm)\n",
    "fig=plt.figure()\n",
    "res=stats.probplot(df_train['GrLivArea'],plot=plt)\n",
    "plt.show()\n",
    "\n",
    "#histogram and normal probability plot\n",
    "sns.distplot(df_train['TotalBsmtSF'], fit=norm);\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(df_train['TotalBsmtSF'], plot=plt)\n",
    "plt.show()\n",
    "\n",
    "#散布図\n",
    "plt.scatter(df_train['GrLivArea'],df_train['SalePrice'])\n",
    "\n",
    "plt.scatter(df_train[df_train['TotalBsmtSF']>0]['TotalBsmtSF'],df_train[df_train['TotalBsmtSF']>0]['SalePrice'])\n",
    "\n",
    "df_train=pd.get_dummies(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ④データ分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
